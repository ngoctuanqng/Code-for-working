--- Tong quan ve code ben duoi:

		üß© 1. MultiTypeKafkaListener ‚Äì Consumer ch√≠nh
		
				ƒê√¢y l√† class ƒë∆∞·ª£c d√πng ƒë·ªÉ l·∫Øng nghe Kafka topic "amface" trong group "deep-fake".

				@KafkaListener l√† annotation trong Spring Kafka d√πng ƒë·ªÉ ƒë√°nh d·∫•u m·ªôt method s·∫Ω nh·∫≠n v√† x·ª≠ l√Ω message t·ª´ Kafka topic m·ªôt c√°ch t·ª± ƒë·ªông.
				T√≥m g·ªçn: N√≥ l√† "consumer listener" ‚Äì khi Kafka c√≥ message m·ªõi, Spring t·ª± ƒë·ªông g·ªçi method c√≥ @KafkaListener.

				üîπ Annotation:
				@KafkaListener(id = "multiGroup1", topics = "amface", groupId = "deep-fake", autoStartup = "false")
				
					topics = "amface": L·∫Øng nghe c√°c message ƒë∆∞·ª£c g·ª≠i ƒë·∫øn topic n√†y.

					groupId = "deep-fake": M·ªói group x·ª≠ l√Ω message ƒë·ªôc l·∫≠p (c√πng 1 message kh√¥ng ƒë∆∞·ª£c g·ª≠i cho 2 consumer c√πng group).

					autoStartup = false: Listener ch∆∞a ch·∫°y ngay khi ·ª©ng d·ª•ng kh·ªüi ƒë·ªông ‚Äì b·∫°n c√≥ th·ªÉ b·∫≠t/t·∫Øt ƒë·ªông n·∫øu c·∫ßn.

				@KafkaHandler ‚Äì x·ª≠ l√Ω message theo lo·∫°i d·ªØ li·ªáu
				
					1.1. H√†m nh·∫≠n ƒë√∫ng object DeepFaceInfoRequest
					@KafkaHandler
					public void handleUserFaceRequest(DeepFaceInfoRequest userFaceRequest)
					Kafka t·ª± ƒë·ªông deserialize JSON ‚Üí DeepFaceInfoRequest (n·∫øu message ƒë√∫ng ƒë·ªãnh d·∫°ng).

					B·∫°n c√≥ th·ªÉ x·ª≠ l√Ω s√¢u t·∫°i ƒë√¢y: g·ªçi service AI, l∆∞u DB, log, ...

					1.2. H√†m x·ª≠ l√Ω chu·ªói JSON th·ªß c√¥ng
					@KafkaHandler
					public void handleUserFaceRequest2(String userFaceRequest)
					N·∫øu Kafka g·ª≠i message d∆∞·ªõi d·∫°ng chu·ªói, h√†m n√†y x·ª≠ l√Ω.

					D√πng ObjectMapper ƒë·ªÉ t·ª± parse chu·ªói th√†nh object.

					G·ªçi h√†m:

					notificationService.createOrUpdateWorkingTime(request);
					‚Üí C√≥ th·ªÉ l√† x·ª≠ l√Ω "gi·ªù v√†o - ra", x√°c ƒë·ªãnh fake hay kh√¥ng.

					Sau ƒë√≥ ƒë·∫©y th√¥ng tin l√™n WebSocket ƒë·ªÉ c√°c client (giao di·ªán) hi·ªÉn th·ªã:

					template.convertAndSend("/topic/check-face-time", request);
					
					1.3. H√†m m·∫∑c ƒë·ªãnh khi kh√¥ng kh·ªõp ki·ªÉu d·ªØ li·ªáu
					@KafkaHandler
					public void unknown(ConsumerRecord<String, Object> record)
					N·∫øu message g·ª≠i l√™n kh√¥ng ph·∫£i String, c≈©ng kh√¥ng ph·∫£i DeepFaceInfoRequest ‚Üí v√†o ƒë√¢y.

					In log ƒë·ªÉ dev bi·∫øt c√≥ g√¨ ƒë√≥ sai.

		üõ† 2. ProductProducer ‚Äì Kafka Producer
		
				Class n√†y ch·ªãu tr√°ch nhi·ªám g·ª≠i message l√™n Kafka.
				
				KafkaTemplate l√† th√†nh ph·∫ßn ch√≠nh ƒë·ªÉ g·ª≠i d·ªØ li·ªáu (message) ƒë·∫øn Kafka topic.

				@Autowired
				private KafkaTemplate<String, String> kafkaTemplate2;
				@Autowired
				private KafkaTemplate<String, DeepFaceInfoRequest> kafkaTemplate;
				H√†m g·ª≠i chu·ªói:
				public void sendToKafka(String message) {
				  kafkaTemplate2.send("deepfake", message);
				}
				H√†m g·ª≠i object:
				public void sendToKafkaJson(DeepFaceInfoRequest message) {
				  kafkaTemplate.send("deepfake", message);
				}
				üëâ G·ª≠i l√™n topic "deepfake".

		‚öôÔ∏è 3. Kafka Consumer Config
		
				ConcurrentKafkaListenerContainerFactory l√† factory (nh√† m√°y) t·∫°o ra container listener ƒë·ªÉ
				x·ª≠ l√Ω c√°c message Kafka g·ª≠i ƒë·∫øn trong Spring Boot. N√≥i ƒë∆°n gi·∫£n: N√≥ c·∫•u h√¨nh c√°ch Spring Boot
				s·∫Ω nh·∫≠n v√† x·ª≠ l√Ω message Kafka th√¥ng qua @KafkaListener.

				ConsumerFactory<K, V> l√† interface trong Spring Kafka d√πng ƒë·ªÉ t·∫°o Kafka Consumer cho vi·ªác ƒë·ªçc message t·ª´ Kafka
				topic. N√≥ l√† ƒë·ªëi x·ª©ng v·ªõi ProducerFactory ‚Äì nh∆∞ng d√†nh cho ph√≠a consumer.
					- ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapAddress:
						ƒê·ªãa ch·ªâ Kafka broker ƒë·ªÉ consumer k·∫øt n·ªëi ƒë·∫øn (VD: "localhost:9092").
						ƒê√¢y l√† ƒëi·ªÉm kh·ªüi ƒë·∫ßu ƒë·ªÉ Kafka Consumer k·∫øt n·ªëi v√†o c·ª•m Kafka.
					- ConsumerConfig.GROUP_ID_CONFIG, groupId:
						ID c·ªßa consumer group m√† consumer n√†y thu·ªôc v·ªÅ.
						Kafka s·ª≠ d·ª•ng group ID ƒë·ªÉ qu·∫£n l√Ω offset v√† c√¢n b·∫±ng t·∫£i gi·ªØa c√°c consumer trong group.
					- ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class:
						Ch·ªâ ƒë·ªãnh l·ªõp d√πng ƒë·ªÉ deserialize key c·ªßa message t·ª´ Kafka.
						Key l√† ki·ªÉu String, n√™n d√πng StringDeserializer.
					- ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class:
						Ch·ªâ ƒë·ªãnh l·ªõp ƒë·ªÉ deserialize value c·ªßa message.
						Value c≈©ng l√† ki·ªÉu String.
					- ConsumerConfig.MAX_PARTITION_FETCH_BYTES_CONFIG, "20971520":
						20971520 byte = 20MB
						S·ªë byte t·ªëi ƒëa consumer ƒë∆∞·ª£c ph√©p fetch t·ª´ 1 partition duy nh·∫•t trong 1 l·∫ßn y√™u c·∫ßu.						
						N·∫øu message l·ªõn, tƒÉng gi√° tr·ªã n√†y ƒë·ªÉ tr√°nh l·ªói record too large.
					- ConsumerConfig.FETCH_MAX_BYTES_CONFIG, "20971520":
						20971520 byte = 20MB
						M√¥ t·∫£: T·ªïng s·ªë byte t·ªëi ƒëa m√† Kafka broker s·∫Ω g·ª≠i v·ªÅ cho consumer trong 1 l·∫ßn fetch, t√≠nh t·ªïng c·∫£ c√°c partition.						
						√ù nghƒ©a: N·∫øu b·∫°n c√≥ nhi·ªÅu partition ƒë∆∞·ª£c assign c√πng l√∫c, gi√° tr·ªã n√†y l√† gi·ªõi h·∫°n chung.

				DefaultKafkaConsumerFactory l√† implementation m·∫∑c ƒë·ªãnh c·ªßa ConsumerFactory trong Spring Kafka, d√πng ƒë·ªÉ t·∫°o ra c√°c Kafka Consumer (ng∆∞·ªùi ti√™u th·ª•)
				v·ªõi c·∫•u h√¨nh b·∫°n cung c·∫•p.
		
				@Bean
				public ConcurrentKafkaListenerContainerFactory<String, DeepFaceInfoRequest> deepFakeKafkaListenerContainerFactory2()
				C·∫•u h√¨nh m·ªôt listener cho topic d·∫°ng object JSON:

				Deserializer s·∫Ω d√πng JsonDeserializer ƒë·ªÉ ƒë·ªçc v√† parse ra DeepFaceInfoRequest.

				Ph·∫£i khai b√°o class r√µ r√†ng ƒë·ªÉ Jackson bi·∫øt deserialize.

		üß™ 4. Kafka Health Check

				HealthIndicator l√† m·ªôt interface trong Spring Boot Actuator, d√πng ƒë·ªÉ ki·ªÉm tra v√† b√°o c√°o tr·∫°ng th√°i "s·ª©c kh·ªèe" (health) c·ªßa
				m·ªôt th√†nh ph·∫ßn trong h·ªá th·ªëng ‚Äî v√≠ d·ª• nh∆∞ Kafka, Database, Redis, RabbitMQ, v.v.

				AdminClient l√† m·ªôt API qu·∫£n l√Ω (administrative) ƒë∆∞·ª£c cung c·∫•p b·ªüi Kafka (trong th∆∞ vi·ªán kafka-clients), cho ph√©p b·∫°n t∆∞∆°ng t√°c
				v√† ƒëi·ªÅu khi·ªÉn c√°c th√†nh ph·∫ßn b√™n trong Kafka nh∆∞: t·∫°o topic, x√≥a topic, li·ªát k√™ topic, xem metadata

				Trong Spring Boot, Health l√† m·ªôt ƒë·ªëi t∆∞·ª£ng ƒë·∫°i di·ªán cho tr·∫°ng th√°i s·ª©c kh·ªèe (health status) c·ªßa m·ªôt th√†nh ph·∫ßn, h·ªá th·ªëng ho·∫∑c to√†n b·ªô ·ª©ng d·ª•ng.

				Trong Kafka, ListTopicsOptions l√† m·ªôt class thu·ªôc Kafka Client Java API, ƒë∆∞·ª£c s·ª≠ d·ª•ng khi b·∫°n mu·ªën li·ªát k√™ danh s√°ch c√°c topic v·ªõi c√°c t√πy ch·ªçn c·ª• th·ªÉ.
		
				@Component("kafka_indicator")
				public class KafkaHealthIndicator implements HealthIndicator
				
				Spring Boot Actuator s·∫Ω g·ªçi h√†m:

				public Health health() {
					AdminClient adminClient = AdminClient.create(props);
					DescribeClusterResult clusterResult = adminClient.describeCluster();
					...
				}
				M·ª•c ƒë√≠ch: ki·ªÉm tra Kafka c√≥ ho·∫°t ƒë·ªông kh√¥ng (ping cluster ID, broker list).

				Tr·∫£ v·ªÅ tr·∫°ng th√°i UP, DOWN cho m√†n h√¨nh health check (ex: /actuator/health).

		‚öíÔ∏è 5. Kafka Producer Config

				ProducerFactory l√† interface do Spring Kafka cung c·∫•p ƒë·ªÉ t·∫°o ra Kafka Producer instance, d√πng ƒë·ªÉ g·ª≠i message (produce message)
				l√™n Kafka. N√≥ l√† ph·∫ßn ‚Äúb√™n g·ª≠i‚Äù c·ªßa Kafka ‚Äî t∆∞∆°ng t·ª± nh∆∞ KafkaTemplate nh∆∞ng ·ªü c·∫•p th·∫•p h∆°n. T·∫°o ra producer ƒë·ªÉ KafkaTemplate d√πng.

				ProducerConfig l√† m·ªôt l·ªõp ti·ªán √≠ch (utility class) trong Spring Kafka / Kafka client Java, ch·ª©a c√°c h·∫±ng s·ªë c·∫•u h√¨nh d√†nh cho
				Kafka Producer. Khi b·∫°n c·∫•u h√¨nh m·ªôt Kafka Producer, b·∫°n s·∫Ω d√πng c√°c key t·ª´ ProducerConfig ƒë·ªÉ truy·ªÅn v√†o Map<String, Object>.
					- ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapAddress:
						Ch·ªâ ƒë·ªãnh danh s√°ch c√°c Kafka broker m√† Producer s·∫Ω k·∫øt n·ªëi ƒë·ªÉ g·ª≠i message.
						bootstrapAddress l√† m·ªôt bi·∫øn ch·ª©a chu·ªói ƒë·ªãa ch·ªâ, v√≠ d·ª•: "localhost:9092" ho·∫∑c "kafka1:9092,kafka2:9092"
					- ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class:
						Ch·ªâ ƒë·ªãnh serializer (b·ªô m√£ h√≥a) d√πng cho key c·ªßa message.
						·ªû ƒë√¢y d√πng StringSerializer, nghƒ©a l√† key s·∫Ω ƒë∆∞·ª£c serialize th√†nh chu·ªói UTF-8 ƒë·ªÉ Kafka hi·ªÉu ƒë∆∞·ª£c.
						B·∫°n c≈©ng c√≥ th·ªÉ d√πng LongSerializer, IntegerSerializer, ho·∫∑c JsonSerializer n·∫øu mu·ªën.
					- ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class:
						Ch·ªâ ƒë·ªãnh serializer d√πng cho value c·ªßa message.
						·ªû ƒë√¢y c≈©ng d√πng StringSerializer, t·ª©c value l√† chu·ªói vƒÉn b·∫£n.
						N·∫øu b·∫°n mu·ªën g·ª≠i object, b·∫°n c√≥ th·ªÉ d√πng JsonSerializer.class.
					- ProducerConfig.MAX_REQUEST_SIZE_CONFIG, "20971520":
						Thi·∫øt l·∫≠p k√≠ch th∆∞·ªõc t·ªëi ƒëa (bytes) cho 1 request g·ª≠i ƒë·∫øn Kafka.
						M·∫∑c ƒë·ªãnh Kafka ch·ªâ cho g·ª≠i t·ªëi ƒëa 1MB (1048576 bytes).						
						·ªû ƒë√¢y b·∫°n tƒÉng l√™n 20MB (20971520 bytes) ƒë·ªÉ c√≥ th·ªÉ g·ª≠i message l·ªõn h∆°n.						
						N·∫øu kh√¥ng set m√† g·ª≠i message l·ªõn, s·∫Ω b·ªã l·ªói RecordTooLargeException.

				DefaultKafkaProducerFactory l√† class m·∫∑c ƒë·ªãnh trong Spring Kafka d√πng ƒë·ªÉ t·∫°o ra Kafka Producer instances d·ª±a tr√™n c·∫•u h√¨nh b·∫°n cung
				c·∫•p. N√≥ l√† implementation c·ªßa interface ProducerFactory<K, V>.
		
				@Bean(name = "kafkaTemplate2")
				public KafkaTemplate<String, String> kafkaTemplate2(...)
				T·∫°o 2 producer:

				M·ªôt producer g·ª≠i message d·∫°ng String.

				M·ªôt producer g·ª≠i message d·∫°ng DeepFaceInfoRequest.

				D√πng JsonSerializer ƒë·ªÉ Kafka t·ª± ƒë·ªông bi·∫øn object th√†nh JSON tr∆∞·ªõc khi g·ª≠i.

		üßæ 6. Kafka Topic Config
		
				KafkaAdmin l√† bean do Spring Kafka cung c·∫•p ƒë·ªÉ gi√∫p b·∫°n t·∫°o v√† qu·∫£n l√Ω c√°c topic Kafka ngay khi ·ª©ng
				d·ª•ng kh·ªüi ƒë·ªông, m√† kh√¥ng c·∫ßn d√πng l·ªánh CLI ho·∫∑c tool ngo√†i.

				AdminClientConfig trong Apache Kafka l√† m·ªôt class ch·ª©a c√°c key c·∫•u h√¨nh d√πng cho AdminClient, m·ªôt API d√πng
				ƒë·ªÉ thao t√°c qu·∫£n tr·ªã Kafka cluster th√¥ng qua Java code (t·∫°o topic, x√≥a topic, danh s√°ch broker, thay ƒë·ªïi partition, v.v.
					- AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG:
						ƒê√¢y l√† h·∫±ng s·ªë key c·∫•u h√¨nh ƒë∆∞·ª£c Kafka cung c·∫•p s·∫µn.
						N√≥ ƒë·∫°i di·ªán cho chu·ªói "bootstrap.servers", d√πng ƒë·ªÉ c·∫•u h√¨nh ƒë·ªãa ch·ªâ c√°c Kafka broker ban ƒë·∫ßu m√† client (·ªü ƒë√¢y l√† AdminClient) c·∫ßn k·∫øt n·ªëi t·ªõi.
						Khi m·ªôt client (producer, consumer, admin) kh·ªüi t·∫°o, n√≥ c·∫ßn bi·∫øt √≠t nh·∫•t m·ªôt broker ƒë·ªÉ c√≥ th·ªÉ k·∫øt n·ªëi v√† kh√°m ph√° to√†n b·ªô cluster.
		
				@Bean
				public KafkaAdmin kafkaAdmin()
				@Bean
				public NewTopic topic()
				T·ª± ƒë·ªông t·∫°o topic "deepfake" (n·∫øu ch∆∞a t·ªìn t·∫°i).

				C√≥ th·ªÉ config: s·ªë partition, replication,...





--- MultiTypeKafkaListener.java


		package com.poscodx.odc.ampro015.config.kafka.listeners;
		import com.poscdx.odc.ampro015.domain.entity.payload.request.DeepFaceInfoRequest;
		import com.poscdx.odc.ampro015.domain.lifecycle.ServiceLifecycle;
		import org.apache.commons.lang3.time.DateUtils;
		import org.apache.kafka.clients.consumer.ConsumerRecord;
		import org.springframework.beans.factory.annotation.Autowired;
		import org.springframework.kafka.annotation.KafkaHandler;
		import org.springframework.kafka.annotation.KafkaListener;
		import org.springframework.stereotype.Component;
		import java.util.Date;
		import java.util.concurrent.TimeoutException;
		@Component
		@KafkaListener(id = "multiGroup1", topics = "amface", groupId = "deep-fake", autoStartup = "false")
		public class MultiTypeKafkaListener {
			@Autowired
			ServiceLifecycle serviceLifecycle;
			@KafkaHandler
			public void handleUserFaceRequest(DeepFaceInfoRequest userFaceRequest) throws TimeoutException {
				try {
					System.out.println("User face received UserFaceRequest 1 (user-face): " + userFaceRequest);
				} catch (Exception e) {
					System.out.println("Handle kafka's message error: " + e.getMessage());
				}
			}
			@KafkaHandler
			public void handleUserFaceRequest2(String userFaceRequest) throws TimeoutException {
				try {
					System.out.println("User face received String 2 (user-face): " + userFaceRequest);
					DeepFaceInfoRequest receiver = DeepFaceInfoRequest.fromJson(userFaceRequest);
					System.out.println("User face received String 2 (Oject): " + receiver);
					serviceLifecycle.requestLevel2WorkingTimeService().createOrUpdateWorkingTime(serviceLifecycle, receiver.getId(), receiver.getAccessTime());
					serviceLifecycle.requestLevel2Service().sendCheckFaceTimeNotification(receiver, "/topic/check-face-time");
				} catch (Exception e) {
					System.out.println("Handle kafka's message error: " + e.getMessage());
				}
			}
			@KafkaHandler
			public void unknown(ConsumerRecord<String, Object> record) throws TimeoutException {
				try {
					System.out.println("User face received Object 2 (user-face): " + record.value());
				} catch (Exception e) {
					System.out.println("Handle kafka's message error: " + e.getMessage());
				}
			}
		}

--- KafkaProducerConfig.java

		package com.poscodx.odc.ampro015.config.kafka;
		import com.poscdx.odc.ampro015.domain.entity.payload.request.DeepFaceInfoRequest;
		import org.apache.kafka.clients.producer.ProducerConfig;
		import org.apache.kafka.common.serialization.StringSerializer;
		import org.springframework.beans.factory.annotation.Value;
		import org.springframework.context.annotation.Bean;
		import org.springframework.context.annotation.Configuration;
		import org.springframework.kafka.core.DefaultKafkaProducerFactory;
		import org.springframework.kafka.core.KafkaTemplate;
		import org.springframework.kafka.core.ProducerFactory;
		import org.springframework.kafka.support.serializer.JsonSerializer;
		import java.util.HashMap;
		import java.util.Map;
		@Configuration
		public class
		KafkaProducerConfig {
			@Value(value = "${spring.kafka.bootstrap-servers}")
			private String bootstrapAddress;
			@Bean
			public ProducerFactory<String, String> producerFactory() {
				Map<String, Object> configProps = new HashMap<>();
				configProps.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapAddress);
				configProps.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
				configProps.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
				configProps.put(ProducerConfig.MAX_REQUEST_SIZE_CONFIG, "20971520");

				return new DefaultKafkaProducerFactory<>(configProps);
			}
			@Bean
			public KafkaTemplate<String, String> kafkaTemplate() {
				return new KafkaTemplate<>(producerFactory());
			}
			@Bean
			public ProducerFactory<String, DeepFaceInfoRequest> userFaceProducerFactory() {
				Map<String, Object> configProps = new HashMap<>();
				configProps.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapAddress);
				configProps.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
				configProps.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, JsonSerializer.class);
				return new DefaultKafkaProducerFactory<>(configProps);
			}
			@Bean
			public KafkaTemplate<String, DeepFaceInfoRequest> userFaceKafkaTemplate() {
				return new KafkaTemplate<>(userFaceProducerFactory());
			}
		}
		
--- ProductProducer.java

		package com.poscodx.odc.ampro015.config.kafka.producers;
		import com.poscdx.odc.ampro015.domain.entity.payload.request.DeepFaceInfoRequest;
		import lombok.NoArgsConstructor;
		import lombok.extern.slf4j.Slf4j;
		import org.springframework.beans.factory.annotation.Autowired;
		import org.springframework.kafka.core.KafkaTemplate;
		import org.springframework.stereotype.Component;
		@Slf4j
		@NoArgsConstructor
		@Component
		public class ProductProducer {
			final String topic = "deepfake";
			@Autowired
			private KafkaTemplate<String, DeepFaceInfoRequest> kafkaTemplate;
			@Autowired
			private KafkaTemplate<String, String> kafkaTemplate2;
			public void sendMessage(String message) {
				kafkaTemplate2.send(topic, message);
				log.info("Send message String: {}", message);
			}
			public void sendMessage(DeepFaceInfoRequest message) {
				kafkaTemplate.send(topic, message);
				log.info("Send message UserFaceRequest: {}", message);
			}
		}
		
--- KafkaConsumerConfig.java		

		package com.poscodx.odc.ampro015.config.kafka;
		import com.poscdx.odc.ampro015.domain.entity.payload.request.DeepFaceInfoRequest;
		import lombok.extern.slf4j.Slf4j;
		import org.apache.kafka.clients.consumer.ConsumerConfig;
		import org.apache.kafka.common.serialization.StringDeserializer;
		import org.springframework.beans.factory.annotation.Value;
		import org.springframework.context.annotation.Bean;
		import org.springframework.context.annotation.Configuration;
		import org.springframework.kafka.config.ConcurrentKafkaListenerContainerFactory;
		import org.springframework.kafka.core.ConsumerFactory;
		import org.springframework.kafka.core.DefaultKafkaConsumerFactory;
		import org.springframework.kafka.support.serializer.JsonDeserializer;
		import java.util.HashMap;
		import java.util.Map;
		@Slf4j
		@Configuration
		public class KafkaConsumerConfig {
			@Value(value = "${spring.kafka.bootstrap-servers}")
			private String bootstrapAddress;
			public ConsumerFactory<String, String> consumerFactory(String groupId) {
				Map<String, Object> props = new HashMap<>();
				props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapAddress);
				props.put(ConsumerConfig.GROUP_ID_CONFIG, groupId);
				props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);
				props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);
				props.put(ConsumerConfig.MAX_PARTITION_FETCH_BYTES_CONFIG, "20971520");
				props.put(ConsumerConfig.FETCH_MAX_BYTES_CONFIG, "20971520");
				return new DefaultKafkaConsumerFactory<>(props);
			}
			public ConcurrentKafkaListenerContainerFactory<String, String> kafkaListenerContainerFactory(String groupId) {
				ConcurrentKafkaListenerContainerFactory<String, String> factory = new ConcurrentKafkaListenerContainerFactory<>();
				factory.setConsumerFactory(consumerFactory(groupId));
				return factory;
			}
			@Bean
			public ConcurrentKafkaListenerContainerFactory<String, String> deepFakeKafkaListenerContainerFactory() {
				return kafkaListenerContainerFactory("deep-fake");
			}
			public ConsumerFactory<String, DeepFaceInfoRequest> consumerFactory2(String groupId) {
				Map<String, Object> props = new HashMap<>();
				props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapAddress);
				props.put(ConsumerConfig.GROUP_ID_CONFIG, groupId);
				return new DefaultKafkaConsumerFactory<>(props, new StringDeserializer(), new JsonDeserializer<>(DeepFaceInfoRequest.class));
			}
			@Bean
			public ConcurrentKafkaListenerContainerFactory<String, DeepFaceInfoRequest> deepFakeeKafkaListenerContainerFactory2() {
				ConcurrentKafkaListenerContainerFactory<String, DeepFaceInfoRequest> factory = new ConcurrentKafkaListenerContainerFactory<>();
				factory.setConsumerFactory(consumerFactory2("deep-fake"));
				return factory;
			}
		}

--- KafkaHealthIndicator.java

		package com.poscodx.odc.ampro015.config.kafka;
		import lombok.extern.slf4j.Slf4j;
		import org.apache.kafka.clients.admin.AdminClient;
		import org.apache.kafka.clients.admin.ListTopicsOptions;
		import org.springframework.beans.factory.annotation.Autowired;
		import org.springframework.boot.actuate.health.Health;
		import org.springframework.boot.actuate.health.HealthIndicator;
		import org.springframework.kafka.core.KafkaAdmin;
		import org.springframework.stereotype.Component;
		import java.util.concurrent.TimeUnit;
		@Component("kafka_indicator")
		@Slf4j
		public class KafkaHealthIndicator implements HealthIndicator {
			@Autowired
			private KafkaAdmin kafkaAdmin;
			@Override
			public Health health() {
				try (AdminClient client = AdminClient.create(kafkaAdmin.getConfig())) {
					client.listTopics(new ListTopicsOptions().timeoutMs(1000)).listings().get(10, TimeUnit.SECONDS);
					return Health.up().build();
				} catch (Exception e) {
					return Health.down().withException(e).build();
				}
			}
		}

--- KafkaTopicConfig.java

		package com.poscodx.odc.ampro015.config.kafka;
		import org.apache.kafka.clients.admin.AdminClientConfig;
		import org.apache.kafka.clients.admin.NewTopic;
		import org.springframework.beans.factory.annotation.Value;
		import org.springframework.context.annotation.Bean;
		import org.springframework.context.annotation.Configuration;
		import org.springframework.kafka.core.KafkaAdmin;
		import java.util.HashMap;
		import java.util.Map;
		@Configuration
		public class KafkaTopicConfig {
			@Value(value = "${spring.kafka.bootstrap-servers}")
			private String bootstrapAddress;
			@Bean
			public KafkaAdmin kafkaAdmin() {
				Map<String, Object> configs = new HashMap<>();
				configs.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapAddress);
				return new KafkaAdmin(configs);
			}
		}			
