--- Tong quan ve code ben duoi:

		üß© 1. MultiTypeKafkaListener ‚Äì Consumer ch√≠nh
		
				ƒê√¢y l√† class ƒë∆∞·ª£c d√πng ƒë·ªÉ l·∫Øng nghe Kafka topic "amface" trong group "deep-fake".

				@KafkaListener l√† annotation trong Spring Kafka d√πng ƒë·ªÉ ƒë√°nh d·∫•u m·ªôt method s·∫Ω nh·∫≠n v√† x·ª≠ l√Ω message t·ª´ Kafka topic m·ªôt c√°ch t·ª± ƒë·ªông.
				T√≥m g·ªçn: N√≥ l√† "consumer listener" ‚Äì khi Kafka c√≥ message m·ªõi, Spring t·ª± ƒë·ªông g·ªçi method c√≥ @KafkaListener.

				üîπ Annotation:
				@KafkaListener(id = "multiGroup1", topics = "amface", groupId = "deep-fake", autoStartup = "false")
				
					topics = "amface": L·∫Øng nghe c√°c message ƒë∆∞·ª£c g·ª≠i ƒë·∫øn topic n√†y.

					groupId = "deep-fake": M·ªói group x·ª≠ l√Ω message ƒë·ªôc l·∫≠p (c√πng 1 message kh√¥ng ƒë∆∞·ª£c g·ª≠i cho 2 consumer c√πng group).

					autoStartup = false: Listener ch∆∞a ch·∫°y ngay khi ·ª©ng d·ª•ng kh·ªüi ƒë·ªông ‚Äì b·∫°n c√≥ th·ªÉ b·∫≠t/t·∫Øt ƒë·ªông n·∫øu c·∫ßn.

				@KafkaHandler ‚Äì x·ª≠ l√Ω message theo lo·∫°i d·ªØ li·ªáu
				
					1.1. H√†m nh·∫≠n ƒë√∫ng object DeepFaceInfoRequest
					@KafkaHandler
					public void handleUserFaceRequest(DeepFaceInfoRequest userFaceRequest)
					Kafka t·ª± ƒë·ªông deserialize JSON ‚Üí DeepFaceInfoRequest (n·∫øu message ƒë√∫ng ƒë·ªãnh d·∫°ng).

					B·∫°n c√≥ th·ªÉ x·ª≠ l√Ω s√¢u t·∫°i ƒë√¢y: g·ªçi service AI, l∆∞u DB, log, ...

					1.2. H√†m x·ª≠ l√Ω chu·ªói JSON th·ªß c√¥ng
					@KafkaHandler
					public void handleUserFaceRequest2(String userFaceRequest)
					N·∫øu Kafka g·ª≠i message d∆∞·ªõi d·∫°ng chu·ªói, h√†m n√†y x·ª≠ l√Ω.

					D√πng ObjectMapper ƒë·ªÉ t·ª± parse chu·ªói th√†nh object.

					G·ªçi h√†m:

					notificationService.createOrUpdateWorkingTime(request);
					‚Üí C√≥ th·ªÉ l√† x·ª≠ l√Ω "gi·ªù v√†o - ra", x√°c ƒë·ªãnh fake hay kh√¥ng.

					Sau ƒë√≥ ƒë·∫©y th√¥ng tin l√™n WebSocket ƒë·ªÉ c√°c client (giao di·ªán) hi·ªÉn th·ªã:

					template.convertAndSend("/topic/check-face-time", request);
					
					1.3. H√†m m·∫∑c ƒë·ªãnh khi kh√¥ng kh·ªõp ki·ªÉu d·ªØ li·ªáu
					@KafkaHandler
					public void unknown(ConsumerRecord<String, Object> record)
					N·∫øu message g·ª≠i l√™n kh√¥ng ph·∫£i String, c≈©ng kh√¥ng ph·∫£i DeepFaceInfoRequest ‚Üí v√†o ƒë√¢y.

					In log ƒë·ªÉ dev bi·∫øt c√≥ g√¨ ƒë√≥ sai.

		üõ† 2. ProductProducer ‚Äì Kafka Producer
		
				Class n√†y ch·ªãu tr√°ch nhi·ªám g·ª≠i message l√™n Kafka.
				
				KafkaTemplate l√† th√†nh ph·∫ßn ch√≠nh ƒë·ªÉ g·ª≠i d·ªØ li·ªáu (message) ƒë·∫øn Kafka topic.

				@Autowired
				private KafkaTemplate<String, String> kafkaTemplate2;
				@Autowired
				private KafkaTemplate<String, DeepFaceInfoRequest> kafkaTemplate;
				H√†m g·ª≠i chu·ªói:
				public void sendToKafka(String message) {
				  kafkaTemplate2.send("deepfake", message);
				}
				H√†m g·ª≠i object:
				public void sendToKafkaJson(DeepFaceInfoRequest message) {
				  kafkaTemplate.send("deepfake", message);
				}
				üëâ G·ª≠i l√™n topic "deepfake".

		‚öôÔ∏è 3. Kafka Consumer Config
		
				ConcurrentKafkaListenerContainerFactory l√† factory (nh√† m√°y) t·∫°o ra container listener ƒë·ªÉ
				x·ª≠ l√Ω c√°c message Kafka g·ª≠i ƒë·∫øn trong Spring Boot. N√≥i ƒë∆°n gi·∫£n: N√≥ c·∫•u h√¨nh c√°ch Spring Boot
				s·∫Ω nh·∫≠n v√† x·ª≠ l√Ω message Kafka th√¥ng qua @KafkaListener.
		
				@Bean
				public ConcurrentKafkaListenerContainerFactory<String, DeepFaceInfoRequest> deepFakeKafkaListenerContainerFactory2()
				C·∫•u h√¨nh m·ªôt listener cho topic d·∫°ng object JSON:

				Deserializer s·∫Ω d√πng JsonDeserializer ƒë·ªÉ ƒë·ªçc v√† parse ra DeepFaceInfoRequest.

				Ph·∫£i khai b√°o class r√µ r√†ng ƒë·ªÉ Jackson bi·∫øt deserialize.

		üß™ 4. Kafka Health Check
		
				KafkaHealthIndicator l√† th√†nh ph·∫ßn c·ªßa Spring Boot Actuator d√πng ƒë·ªÉ ki·ªÉm tra t√¨nh tr·∫°ng k·∫øt n·ªëi c·ªßa ·ª©ng d·ª•ng v·ªõi Kafka.
		
				@Component("kafka_indicator")
				public class KafkaHealthIndicator implements HealthIndicator
				
				Spring Boot Actuator s·∫Ω g·ªçi h√†m:

				public Health health() {
					AdminClient adminClient = AdminClient.create(props);
					DescribeClusterResult clusterResult = adminClient.describeCluster();
					...
				}
				M·ª•c ƒë√≠ch: ki·ªÉm tra Kafka c√≥ ho·∫°t ƒë·ªông kh√¥ng (ping cluster ID, broker list).

				Tr·∫£ v·ªÅ tr·∫°ng th√°i UP, DOWN cho m√†n h√¨nh health check (ex: /actuator/health).

		‚öíÔ∏è 5. Kafka Producer Config
		
				@Bean(name = "kafkaTemplate2")
				public KafkaTemplate<String, String> kafkaTemplate2(...)
				T·∫°o 2 producer:

				M·ªôt producer g·ª≠i message d·∫°ng String.

				M·ªôt producer g·ª≠i message d·∫°ng DeepFaceInfoRequest.

				D√πng JsonSerializer ƒë·ªÉ Kafka t·ª± ƒë·ªông bi·∫øn object th√†nh JSON tr∆∞·ªõc khi g·ª≠i.

		üßæ 6. Kafka Topic Config
		
				KafkaAdmin l√† bean do Spring Kafka cung c·∫•p ƒë·ªÉ gi√∫p b·∫°n t·∫°o v√† qu·∫£n l√Ω c√°c topic Kafka ngay khi ·ª©ng
				d·ª•ng kh·ªüi ƒë·ªông, m√† kh√¥ng c·∫ßn d√πng l·ªánh CLI ho·∫∑c tool ngo√†i.
		
				@Bean
				public KafkaAdmin kafkaAdmin()
				@Bean
				public NewTopic topic()
				T·ª± ƒë·ªông t·∫°o topic "deepfake" (n·∫øu ch∆∞a t·ªìn t·∫°i).

				C√≥ th·ªÉ config: s·ªë partition, replication,...





--- MultiTypeKafkaListener.java


		package com.poscodx.odc.ampro015.config.kafka.listeners;
		import com.poscdx.odc.ampro015.domain.entity.payload.request.DeepFaceInfoRequest;
		import com.poscdx.odc.ampro015.domain.lifecycle.ServiceLifecycle;
		import org.apache.commons.lang3.time.DateUtils;
		import org.apache.kafka.clients.consumer.ConsumerRecord;
		import org.springframework.beans.factory.annotation.Autowired;
		import org.springframework.kafka.annotation.KafkaHandler;
		import org.springframework.kafka.annotation.KafkaListener;
		import org.springframework.stereotype.Component;
		import java.util.Date;
		import java.util.concurrent.TimeoutException;
		@Component
		@KafkaListener(id = "multiGroup1", topics = "amface", groupId = "deep-fake", autoStartup = "false")
		public class MultiTypeKafkaListener {
			@Autowired
			ServiceLifecycle serviceLifecycle;
			@KafkaHandler
			public void handleUserFaceRequest(DeepFaceInfoRequest userFaceRequest) throws TimeoutException {
				try {
					System.out.println("User face received UserFaceRequest 1 (user-face): " + userFaceRequest);
				} catch (Exception e) {
					System.out.println("Handle kafka's message error: " + e.getMessage());
				}
			}
			@KafkaHandler
			public void handleUserFaceRequest2(String userFaceRequest) throws TimeoutException {
				try {
					System.out.println("User face received String 2 (user-face): " + userFaceRequest);
					DeepFaceInfoRequest receiver = DeepFaceInfoRequest.fromJson(userFaceRequest);
					System.out.println("User face received String 2 (Oject): " + receiver);
					serviceLifecycle.requestLevel2WorkingTimeService().createOrUpdateWorkingTime(serviceLifecycle, receiver.getId(), receiver.getAccessTime());
					serviceLifecycle.requestLevel2Service().sendCheckFaceTimeNotification(receiver, "/topic/check-face-time");
				} catch (Exception e) {
					System.out.println("Handle kafka's message error: " + e.getMessage());
				}
			}
			@KafkaHandler
			public void unknown(ConsumerRecord<String, Object> record) throws TimeoutException {
				try {
					System.out.println("User face received Object 2 (user-face): " + record.value());
				} catch (Exception e) {
					System.out.println("Handle kafka's message error: " + e.getMessage());
				}
			}
		}
		
--- ProductProducer.java

		package com.poscodx.odc.ampro015.config.kafka.producers;
		import com.poscdx.odc.ampro015.domain.entity.payload.request.DeepFaceInfoRequest;
		import lombok.NoArgsConstructor;
		import lombok.extern.slf4j.Slf4j;
		import org.springframework.beans.factory.annotation.Autowired;
		import org.springframework.kafka.core.KafkaTemplate;
		import org.springframework.stereotype.Component;
		@Slf4j
		@NoArgsConstructor
		@Component
		public class ProductProducer {
			final String topic = "deepfake";
			@Autowired
			private KafkaTemplate<String, DeepFaceInfoRequest> kafkaTemplate;
			@Autowired
			private KafkaTemplate<String, String> kafkaTemplate2;
			public void sendMessage(String message) {
				kafkaTemplate2.send(topic, message);
				log.info("Send message String: {}", message);
			}
			public void sendMessage(DeepFaceInfoRequest message) {
				kafkaTemplate.send(topic, message);
				log.info("Send message UserFaceRequest: {}", message);
			}
		}
		
--- KafkaConsumerConfig.java		

		package com.poscodx.odc.ampro015.config.kafka;
		import com.poscdx.odc.ampro015.domain.entity.payload.request.DeepFaceInfoRequest;
		import lombok.extern.slf4j.Slf4j;
		import org.apache.kafka.clients.consumer.ConsumerConfig;
		import org.apache.kafka.common.serialization.StringDeserializer;
		import org.springframework.beans.factory.annotation.Value;
		import org.springframework.context.annotation.Bean;
		import org.springframework.context.annotation.Configuration;
		import org.springframework.kafka.config.ConcurrentKafkaListenerContainerFactory;
		import org.springframework.kafka.core.ConsumerFactory;
		import org.springframework.kafka.core.DefaultKafkaConsumerFactory;
		import org.springframework.kafka.support.serializer.JsonDeserializer;
		import java.util.HashMap;
		import java.util.Map;
		@Slf4j
		@Configuration
		public class KafkaConsumerConfig {
			@Value(value = "${spring.kafka.bootstrap-servers}")
			private String bootstrapAddress;
			public ConsumerFactory<String, String> consumerFactory(String groupId) {
				Map<String, Object> props = new HashMap<>();
				props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapAddress);
				props.put(ConsumerConfig.GROUP_ID_CONFIG, groupId);
				props.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);
				props.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);
				props.put(ConsumerConfig.MAX_PARTITION_FETCH_BYTES_CONFIG, "20971520");
				props.put(ConsumerConfig.FETCH_MAX_BYTES_CONFIG, "20971520");
				return new DefaultKafkaConsumerFactory<>(props);
			}
			public ConcurrentKafkaListenerContainerFactory<String, String> kafkaListenerContainerFactory(String groupId) {
				ConcurrentKafkaListenerContainerFactory<String, String> factory = new ConcurrentKafkaListenerContainerFactory<>();
				factory.setConsumerFactory(consumerFactory(groupId));
				return factory;
			}
			@Bean
			public ConcurrentKafkaListenerContainerFactory<String, String> deepFakeKafkaListenerContainerFactory() {
				return kafkaListenerContainerFactory("deep-fake");
			}
			public ConsumerFactory<String, DeepFaceInfoRequest> consumerFactory2(String groupId) {
				Map<String, Object> props = new HashMap<>();
				props.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapAddress);
				props.put(ConsumerConfig.GROUP_ID_CONFIG, groupId);
				return new DefaultKafkaConsumerFactory<>(props, new StringDeserializer(), new JsonDeserializer<>(DeepFaceInfoRequest.class));
			}
			@Bean
			public ConcurrentKafkaListenerContainerFactory<String, DeepFaceInfoRequest> deepFakeeKafkaListenerContainerFactory2() {
				ConcurrentKafkaListenerContainerFactory<String, DeepFaceInfoRequest> factory = new ConcurrentKafkaListenerContainerFactory<>();
				factory.setConsumerFactory(consumerFactory2("deep-fake"));
				return factory;
			}
		}

--- KafkaHealthIndicator.java

		package com.poscodx.odc.ampro015.config.kafka;
		import lombok.extern.slf4j.Slf4j;
		import org.apache.kafka.clients.admin.AdminClient;
		import org.apache.kafka.clients.admin.ListTopicsOptions;
		import org.springframework.beans.factory.annotation.Autowired;
		import org.springframework.boot.actuate.health.Health;
		import org.springframework.boot.actuate.health.HealthIndicator;
		import org.springframework.kafka.core.KafkaAdmin;
		import org.springframework.stereotype.Component;
		import java.util.concurrent.TimeUnit;
		@Component("kafka_indicator")
		@Slf4j
		public class KafkaHealthIndicator implements HealthIndicator {
			@Autowired
			private KafkaAdmin kafkaAdmin;
			@Override
			public Health health() {
				try (AdminClient client = AdminClient.create(kafkaAdmin.getConfig())) {
					client.listTopics(new ListTopicsOptions().timeoutMs(1000)).listings().get(10, TimeUnit.SECONDS);
					return Health.up().build();
				} catch (Exception e) {
					return Health.down().withException(e).build();
				}
			}
		}

--- KafkaProducerConfig.java

		package com.poscodx.odc.ampro015.config.kafka;
		import com.poscdx.odc.ampro015.domain.entity.payload.request.DeepFaceInfoRequest;
		import org.apache.kafka.clients.producer.ProducerConfig;
		import org.apache.kafka.common.serialization.StringSerializer;
		import org.springframework.beans.factory.annotation.Value;
		import org.springframework.context.annotation.Bean;
		import org.springframework.context.annotation.Configuration;
		import org.springframework.kafka.core.DefaultKafkaProducerFactory;
		import org.springframework.kafka.core.KafkaTemplate;
		import org.springframework.kafka.core.ProducerFactory;
		import org.springframework.kafka.support.serializer.JsonSerializer;
		import java.util.HashMap;
		import java.util.Map;
		@Configuration
		public class
		KafkaProducerConfig {
			@Value(value = "${spring.kafka.bootstrap-servers}")
			private String bootstrapAddress;
			@Bean
			public ProducerFactory<String, String> producerFactory() {
				Map<String, Object> configProps = new HashMap<>();
				configProps.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapAddress);
				configProps.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
				configProps.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
				configProps.put(ProducerConfig.MAX_REQUEST_SIZE_CONFIG, "20971520");

				return new DefaultKafkaProducerFactory<>(configProps);
			}
			@Bean
			public KafkaTemplate<String, String> kafkaTemplate() {
				return new KafkaTemplate<>(producerFactory());
			}
			@Bean
			public ProducerFactory<String, DeepFaceInfoRequest> userFaceProducerFactory() {
				Map<String, Object> configProps = new HashMap<>();
				configProps.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapAddress);
				configProps.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);
				configProps.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, JsonSerializer.class);
				return new DefaultKafkaProducerFactory<>(configProps);
			}
			@Bean
			public KafkaTemplate<String, DeepFaceInfoRequest> userFaceKafkaTemplate() {
				return new KafkaTemplate<>(userFaceProducerFactory());
			}
		}

--- KafkaTopicConfig.java

		package com.poscodx.odc.ampro015.config.kafka;
		import org.apache.kafka.clients.admin.AdminClientConfig;
		import org.apache.kafka.clients.admin.NewTopic;
		import org.springframework.beans.factory.annotation.Value;
		import org.springframework.context.annotation.Bean;
		import org.springframework.context.annotation.Configuration;
		import org.springframework.kafka.core.KafkaAdmin;
		import java.util.HashMap;
		import java.util.Map;
		@Configuration
		public class KafkaTopicConfig {
			@Value(value = "${spring.kafka.bootstrap-servers}")
			private String bootstrapAddress;
			@Bean
			public KafkaAdmin kafkaAdmin() {
				Map<String, Object> configs = new HashMap<>();
				configs.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapAddress);
				return new KafkaAdmin(configs);
			}
		}			
